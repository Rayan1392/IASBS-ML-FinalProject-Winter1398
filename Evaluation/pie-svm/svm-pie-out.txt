Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 19:29:22) [MSC v.1916 32 bit (Intel)] on win32
Type "help", "copyright", "credits" or "license()" for more information.
>>> 
============= RESTART: F:\982\ml\FinalProject\PIE\svm-pie-fun.py =============
Traceback (most recent call last):
  File "F:\982\ml\FinalProject\PIE\svm-pie-fun.py", line 50, in <module>
    X_cross = np.concatenate([x_temp[0],x_temp[1],x_temp[2],x_temp[3]])
NameError: name 'x_temp' is not defined
>>> 
============= RESTART: F:\982\ml\FinalProject\PIE\svm-pie-fun.py =============

Warning (from warnings module):
  File "C:\Users\behnia-pc\AppData\Local\Programs\Python\Python37-32\lib\site-packages\sklearn\metrics\classification.py", line 1437
    'precision', 'predicted', average, warn_for)
UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
              precision    recall  f1-score   support

           1       0.91      0.61      0.73        49
           2       0.00      0.00      0.00        49
           3       0.87      0.92      0.89        49
           4       1.00      0.24      0.39        49
           5       0.97      0.76      0.85        49
           6       0.70      0.71      0.71        49
           7       1.00      0.35      0.52        49
           8       1.00      0.53      0.69        49
           9       0.83      0.20      0.33        49
          10       0.78      1.00      0.88        49
          11       0.85      0.35      0.49        49
          12       0.82      0.67      0.74        49
          13       0.97      0.63      0.77        49
          14       1.00      0.12      0.22        49
          15       1.00      0.51      0.68        49
          16       0.21      0.37      0.27        49
          17       1.00      0.90      0.95        49
          18       0.94      0.31      0.46        49
          19       1.00      0.06      0.12        49
          20       0.55      0.96      0.70        49
          21       1.00      0.27      0.42        49
          22       0.36      0.98      0.52        49
          23       0.89      0.51      0.65        49
          24       0.92      0.49      0.64        49
          25       1.00      0.24      0.39        49
          26       0.00      0.00      0.00        49
          27       1.00      0.49      0.66        49
          28       0.50      0.02      0.04        49
          29       1.00      0.06      0.12        49
          30       0.14      0.35      0.20        49
          31       0.58      0.29      0.38        49
          32       0.89      0.63      0.74        49
          33       0.28      0.92      0.42        49
          34       1.00      0.14      0.25        49
          35       0.49      0.98      0.65        49
          36       0.96      0.98      0.97        49
          37       0.45      0.35      0.39        49
          38       0.71      0.96      0.82        49
          39       1.00      0.37      0.54        49
          40       1.00      0.94      0.97        49
          41       0.81      0.35      0.49        49
          42       0.88      0.86      0.87        49
          43       0.92      0.24      0.39        49
          44       0.88      0.31      0.45        49
          45       0.46      0.43      0.44        49
          46       0.97      0.63      0.77        49
          47       0.80      0.80      0.80        49
          48       0.96      0.96      0.96        49
          49       1.00      0.59      0.74        49
          50       0.71      0.10      0.18        49
          51       0.07      1.00      0.12        49
          52       0.88      0.73      0.80        49
          53       1.00      0.53      0.69        49
          54       0.73      0.76      0.74        49
          55       1.00      0.67      0.80        49
          56       0.94      0.33      0.48        49
          57       1.00      0.53      0.69        49
          58       0.41      0.88      0.56        49
          59       1.00      0.31      0.47        49
          60       0.97      0.73      0.84        49
          61       1.00      0.98      0.99        49
          62       0.73      0.65      0.69        49
          63       0.15      0.37      0.21        49
          64       0.58      0.22      0.32        49
          65       0.37      0.41      0.39        49
          66       0.47      0.14      0.22        49
          67       1.00      0.37      0.54        49
          68       0.61      0.41      0.49        49

    accuracy                           0.52      3332
   macro avg       0.76      0.52      0.55      3332
weighted avg       0.76      0.52      0.55      3332


Warning (from warnings module):
  File "C:\Users\behnia-pc\AppData\Local\Programs\Python\Python37-32\lib\site-packages\sklearn\metrics\classification.py", line 1437
    'precision', 'predicted', average, warn_for)
UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
              precision    recall  f1-score   support

           1       0.91      0.83      0.87        24
           2       1.00      0.04      0.08        24
           3       0.92      0.46      0.61        24
           4       1.00      0.04      0.08        24
           5       1.00      0.88      0.93        24
           6       1.00      1.00      1.00        24
           7       0.89      0.71      0.79        24
           8       0.81      0.88      0.84        24
           9       0.14      0.08      0.11        24
          10       0.89      1.00      0.94        24
          11       1.00      0.54      0.70        24
          12       1.00      0.71      0.83        24
          13       0.84      0.88      0.86        24
          14       1.00      0.62      0.77        24
          15       0.29      0.83      0.43        24
          16       1.00      0.79      0.88        24
          17       0.45      0.79      0.58        24
          18       0.53      0.71      0.61        24
          19       0.00      0.00      0.00        24
          20       0.56      1.00      0.72        24
          21       0.81      0.71      0.76        24
          22       0.69      1.00      0.81        24
          23       0.85      0.96      0.90        24
          24       0.71      1.00      0.83        24
          25       1.00      0.79      0.88        24
          26       1.00      0.83      0.91        24
          27       0.91      0.42      0.57        24
          28       0.50      0.04      0.08        24
          29       0.00      0.00      0.00        24
          30       0.85      0.71      0.77        24
          31       0.86      0.25      0.39        24
          32       0.89      0.71      0.79        24
          33       0.71      0.42      0.53        24
          34       0.00      0.00      0.00        24
          35       0.88      0.62      0.73        24
          36       1.00      0.92      0.96        24
          37       0.18      0.38      0.25        24
          38       0.95      0.95      0.95        21
          39       1.00      0.42      0.59        24
          40       0.79      0.92      0.85        24
          41       0.95      0.83      0.89        24
          42       0.20      0.04      0.07        24
          43       0.84      0.88      0.86        24
          44       0.80      0.83      0.82        24
          45       0.67      0.83      0.74        24
          46       1.00      0.79      0.88        24
          47       0.50      0.04      0.08        24
          48       1.00      0.96      0.98        24
          49       0.88      0.29      0.44        24
          50       1.00      0.50      0.67        24
          51       0.62      1.00      0.76        24
          52       0.88      0.88      0.88        24
          53       1.00      0.33      0.50        24
          54       1.00      0.96      0.98        24
          55       0.96      0.96      0.96        24
          56       0.78      0.58      0.67        24
          57       0.81      0.92      0.86        24
          58       1.00      0.92      0.96        24
          59       1.00      0.58      0.74        24
          60       0.11      0.96      0.19        24
          61       0.58      0.88      0.70        24
          62       1.00      0.83      0.91        24
          63       0.66      0.79      0.72        24
          64       0.95      0.83      0.89        24
          65       0.61      0.83      0.70        24
          66       0.00      0.00      0.00        24
          67       0.87      0.83      0.85        24
          68       0.18      0.08      0.11        24

    accuracy                           0.65      1629
   macro avg       0.74      0.65      0.65      1629
weighted avg       0.74      0.65      0.65      1629

              precision    recall  f1-score   support

           1       1.00      1.00      1.00        24
           2       0.33      0.08      0.13        24
           3       0.96      0.96      0.96        24
           4       0.91      0.83      0.87        24
           5       0.70      0.88      0.78        24
           6       0.91      0.83      0.87        24
           7       0.85      0.71      0.77        24
           8       0.87      0.83      0.85        24
           9       0.94      0.71      0.81        24
          10       0.39      1.00      0.56        24
          11       1.00      0.04      0.08        24
          12       0.59      0.71      0.64        24
          13       0.95      0.79      0.86        24
          14       1.00      0.88      0.93        24
          15       0.91      0.88      0.89        24
          16       0.83      0.21      0.33        24
          17       0.76      0.92      0.83        24
          18       0.85      0.46      0.59        24
          19       0.90      0.79      0.84        24
          20       0.88      0.96      0.92        24
          21       1.00      0.75      0.86        24
          22       0.86      1.00      0.92        24
          23       0.96      1.00      0.98        24
          24       1.00      1.00      1.00        24
          25       0.17      0.21      0.19        24
          26       0.64      0.38      0.47        24
          27       1.00      0.79      0.88        24
          28       0.33      0.04      0.07        24
          29       0.00      0.00      0.00        24
          30       1.00      0.71      0.83        24
          31       0.71      0.92      0.80        24
          32       0.68      0.62      0.65        24
          33       1.00      0.67      0.80        24
          34       0.95      0.75      0.84        24
          35       0.50      0.92      0.65        24
          36       0.85      0.92      0.88        24
          37       0.80      0.67      0.73        24
          38       0.96      1.00      0.98        24
          39       0.71      0.71      0.71        24
          40       1.00      0.88      0.93        24
          41       0.92      0.46      0.61        24
          42       1.00      0.83      0.91        24
          43       0.94      0.67      0.78        24
          44       0.50      0.92      0.65        24
          45       0.83      0.79      0.81        24
          46       0.18      0.96      0.30        24
          47       0.88      0.92      0.90        24
          48       0.80      1.00      0.89        24
          49       0.73      0.92      0.81        24
          50       0.05      0.04      0.05        24
          51       0.67      1.00      0.80        24
          52       0.71      0.62      0.67        24
          53       0.89      0.67      0.76        24
          54       1.00      0.92      0.96        24
          55       0.81      0.71      0.76        24
          56       0.87      0.54      0.67        24
          57       0.41      0.38      0.39        24
          58       0.95      0.83      0.89        24
          59       0.95      0.79      0.86        24
          60       0.96      1.00      0.98        24
          61       0.86      1.00      0.92        24
          62       0.95      0.88      0.91        24
          63       0.95      0.83      0.89        24
          64       0.53      0.33      0.41        24
          65       0.96      0.96      0.96        24
          66       0.53      0.83      0.65        24
          67       0.63      0.50      0.56        24
          68       1.00      0.92      0.96        24

    accuracy                           0.73      1632
   macro avg       0.78      0.73      0.73      1632
weighted avg       0.78      0.73      0.73      1632

              precision    recall  f1-score   support

           1       0.96      0.94      0.95        49
           2       0.77      0.41      0.53        49
           3       0.96      0.90      0.93        49
           4       1.00      0.86      0.92        49
           5       0.97      0.65      0.78        49
           6       1.00      0.88      0.93        49
           7       0.95      0.73      0.83        49
           8       0.94      0.92      0.93        49
           9       1.00      0.94      0.97        49
          10       0.92      1.00      0.96        49
          11       0.89      0.65      0.75        49
          12       0.65      0.71      0.68        49
          13       0.96      0.92      0.94        49
          14       0.96      0.98      0.97        49
          15       0.92      1.00      0.96        49
          16       0.95      0.41      0.57        49
          17       0.74      0.98      0.84        49
          18       1.00      0.96      0.98        49
          19       0.96      0.92      0.94        49
          20       0.98      1.00      0.99        49
          21       0.98      0.98      0.98        49
          22       0.62      0.90      0.73        49
          23       0.86      1.00      0.92        49
          24       0.86      1.00      0.92        49
          25       0.39      0.84      0.53        49
          26       0.88      0.90      0.89        49
          27       0.96      0.96      0.96        49
          28       1.00      0.71      0.83        49
          29       0.94      0.33      0.48        49
          30       0.96      0.92      0.94        49
          31       0.97      0.76      0.85        49
          32       1.00      0.67      0.80        49
          33       1.00      0.73      0.85        49
          34       0.93      0.88      0.91        49
          35       1.00      1.00      1.00        49
          36       0.89      0.98      0.93        49
          37       0.92      0.71      0.80        49
          38       0.98      1.00      0.99        46
          39       0.93      0.88      0.91        49
          40       1.00      0.98      0.99        49
          41       0.60      0.94      0.73        49
          42       0.81      0.80      0.80        49
          43       0.98      0.86      0.91        49
          44       1.00      0.86      0.92        49
          45       1.00      0.96      0.98        49
          46       0.73      0.98      0.83        49
          47       0.96      0.94      0.95        49
          48       1.00      0.96      0.98        49
          49       0.84      0.94      0.88        49
          50       1.00      0.55      0.71        49
          51       1.00      1.00      1.00        49
          52       0.91      0.80      0.85        49
          53       0.75      0.86      0.80        49
          54       0.89      0.96      0.92        49
          55       0.93      0.84      0.88        49
          56       0.86      0.65      0.74        49
          57       0.97      0.57      0.72        49
          58       0.95      0.84      0.89        49
          59       0.96      0.94      0.95        49
          60       1.00      0.98      0.99        49
          61       0.35      1.00      0.52        49
          62       0.87      0.98      0.92        49
          63       1.00      0.96      0.98        49
          64       1.00      0.92      0.96        49
          65       0.49      1.00      0.66        49
          66       1.00      0.88      0.93        49
          67       1.00      0.71      0.83        49
          68       0.88      0.90      0.89        49

    accuracy                           0.86      3329
   macro avg       0.90      0.86      0.86      3329
weighted avg       0.90      0.86      0.86      3329


Warning (from warnings module):
  File "C:\Users\behnia-pc\AppData\Local\Programs\Python\Python37-32\lib\site-packages\sklearn\metrics\classification.py", line 1437
    'precision', 'predicted', average, warn_for)
UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
              precision    recall  f1-score   support

           1       0.77      0.83      0.80        24
           2       0.00      0.00      0.00        24
           3       0.78      0.88      0.82        24
           4       0.56      0.92      0.70        24
           5       0.29      0.08      0.13        24
           6       0.68      0.88      0.76        24
           7       0.00      0.00      0.00        24
           8       0.90      0.38      0.53        24
           9       0.90      0.79      0.84        24
          10       1.00      0.83      0.91        24
          11       1.00      0.17      0.29        24
          12       0.00      0.00      0.00        24
          13       0.71      0.71      0.71        24
          14       0.84      0.88      0.86        24
          15       0.33      0.79      0.46        24
          16       0.90      0.38      0.53        24
          17       0.15      0.67      0.25        24
          18       0.68      0.79      0.73        24
          19       0.00      0.00      0.00        24
          20       0.83      0.79      0.81        24
          21       1.00      0.21      0.34        24
          22       0.73      1.00      0.84        24
          23       0.85      0.71      0.77        24
          24       0.95      0.88      0.91        24
          25       0.02      0.12      0.03        24
          26       0.60      0.25      0.35        24
          27       0.76      0.79      0.78        24
          28       0.00      0.00      0.00        24
          29       0.00      0.00      0.00        24
          30       0.81      0.54      0.65        24
          31       0.62      0.33      0.43        24
          32       0.87      0.54      0.67        24
          33       0.50      0.21      0.29        24
          34       1.00      0.38      0.55        24
          35       0.67      0.92      0.77        24
          36       0.35      0.96      0.52        24
          37       0.47      0.38      0.42        24
          38       1.00      1.00      1.00        24
          39       0.81      0.71      0.76        24
          40       0.53      0.96      0.69        24
          41       0.94      0.67      0.78        24
          42       0.80      0.67      0.73        24
          43       0.71      0.83      0.77        24
          44       1.00      0.62      0.77        24
          45       0.61      0.71      0.65        24
          46       0.91      0.83      0.87        24
          47       0.91      0.83      0.87        24
          48       0.94      0.71      0.81        24
          49       0.78      0.88      0.82        24
          50       0.35      0.50      0.41        24
          51       0.32      1.00      0.48        24
          52       0.50      0.12      0.20        24
          53       0.75      0.25      0.38        24
          54       0.59      0.79      0.68        24
          55       0.89      0.67      0.76        24
          56       1.00      0.04      0.08        24
          57       0.91      0.83      0.87        24
          58       0.26      0.88      0.40        24
          59       0.91      0.88      0.89        24
          60       1.00      0.83      0.91        24
          61       1.00      0.88      0.93        24
          62       0.00      0.00      0.00        24
          63       1.00      0.58      0.74        24
          64       1.00      0.21      0.34        24
          65       0.67      0.83      0.74        24
          66       0.75      0.25      0.38        24
          67       1.00      0.25      0.40        24
          68       1.00      0.25      0.40        24

    accuracy                           0.56      1632
   macro avg       0.67      0.56      0.56      1632
weighted avg       0.67      0.56      0.56      1632

>>> 
