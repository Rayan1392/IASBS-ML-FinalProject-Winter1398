=== PIE: Bayesian Logistic Regression ===
              precision    recall  f1-score   support

           1       1.00      0.95      0.98       170
           2       0.99      0.99      0.99       170
           3       0.96      0.94      0.95       170
           4       0.99      0.99      0.99       170
           5       0.89      0.99      0.94       170
           6       1.00      0.96      0.98       170
           7       1.00      0.94      0.97       170
           8       0.98      0.95      0.97       170
           9       0.75      0.99      0.85       170
          10       1.00      1.00      1.00       170
          11       0.99      0.98      0.99       170
          12       1.00      0.76      0.86       170
          13       1.00      0.98      0.99       170
          14       0.99      0.99      0.99       170
          15       0.99      0.99      0.99       170
          16       0.89      0.92      0.90       170
          17       0.98      0.99      0.99       170
          18       0.99      0.95      0.97       170
          19       0.98      0.95      0.96       170
          20       1.00      1.00      1.00       170
          21       0.99      0.99      0.99       170
          22       1.00      0.30      0.46       170
          23       0.94      0.98      0.96       170
          24       1.00      1.00      1.00       170
          25       0.83      0.99      0.91       170
          26       0.96      0.95      0.96       170
          27       0.98      0.93      0.95       170
          28       0.91      0.85      0.88       170
          29       0.97      0.92      0.95       170
          30       0.84      0.99      0.91       170
          31       0.96      0.88      0.91       170
          32       0.94      0.96      0.95       170
          33       0.96      0.92      0.94       170
          34       0.90      0.95      0.92       170
          35       1.00      0.98      0.99       170
          36       1.00      1.00      1.00       170
          37       0.96      0.94      0.95       170
          38       0.99      1.00      1.00       164
          39       0.99      1.00      0.99       170
          40       1.00      0.98      0.99       170
          41       0.99      0.97      0.98       170
          42       0.90      0.98      0.94       170
          43       1.00      0.98      0.99       170
          44       0.99      0.98      0.98       170
          45       0.99      0.92      0.95       170
          46       0.97      0.97      0.97       170
          47       0.92      0.96      0.94       170
          48       0.99      0.99      0.99       170
          49       0.81      0.99      0.89       170
          50       0.99      0.97      0.98       170
          51       1.00      1.00      1.00       170
          52       0.98      0.97      0.98       170
          53       0.94      0.96      0.95       170
          54       0.93      0.99      0.96       170
          55       0.92      0.98      0.95       170
          56       0.88      0.98      0.92       170
          57       1.00      0.97      0.99       170
          58       0.98      0.95      0.96       170
          59       0.92      0.98      0.95       170
          60       1.00      1.00      1.00       170
          61       0.97      1.00      0.98       170
          62       1.00      0.98      0.99       170
          63       1.00      0.88      0.93       170
          64       0.95      0.98      0.96       170
          65       0.90      1.00      0.95       170
          66       0.95      0.96      0.96       170
          67       0.87      0.98      0.92       170
          68       0.98      0.97      0.98       170

    accuracy                           0.95     11554
   macro avg       0.96      0.96      0.95     11554
weighted avg       0.96      0.95      0.95     11554